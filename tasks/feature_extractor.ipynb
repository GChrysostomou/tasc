{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label', 'exp_split'], dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "dataset = \"mimicanemia\"\n",
    "\n",
    "text_data = pd.read_csv(dataset + \"/\"+dataset+\"_dataset.csv\")\n",
    "\n",
    "text_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_data = text_data[(text_data[\"exp_split\"] == \"train\") | (text_data[\"exp_split\"] == \"dev\")]\n",
    "\n",
    "text_data[\"text\"] = text_data[\"text\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = [\"<SOS>\", \"<EOS>\"]\n",
    "\n",
    "text_data['text'] = text_data['text'].apply(lambda x: \" \".join([item for item in x.split() if item not in stop]))\n",
    "\n",
    "data = pickle.load(open(dataset + \"/data.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "probs_dict = {}\n",
    "\n",
    "tf = Counter()\n",
    "tf[\"<PAD>\"] = 0\n",
    "tf[\"<SOS>\"] = 0\n",
    "tf[\"<EOS>\"] = 0\n",
    "tf[\"<UNKN>\"] = 0\n",
    "\n",
    "n_docs = len(text_data.text)\n",
    "\n",
    "df = Counter(dict(zip(set(data.w2ix.keys()), [0]*len(data.w2ix))))\n",
    "\n",
    "for doc in text_data.text:\n",
    "\n",
    "    df_temp = Counter(set(doc.split()))\n",
    "    tf.update(doc.split())\n",
    "    df.update(df_temp)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "idf = {k:np.log(n_docs/v) if v > 0 else v for k,v in df.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = {}\n",
    "\n",
    "for word in tf.keys():\n",
    "    \n",
    "     tfidf[word] = tf[word]*idf[word]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56152"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56152"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.w2ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = {data.w2ix[k]:v for k,v in tfidf.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(sort, open(dataset + \"/tfidf.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
